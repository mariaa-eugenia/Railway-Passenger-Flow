{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\maria\\anaconda3\\envs\\dataanalytics\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\maria\\anaconda3\\envs\\dataanalytics\\lib\\site-packages (from openpyxl) (2.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'region'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\maria\\anaconda3\\envs\\DataAnalytics\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'region'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Merge with region info\u001b[39;00m\n\u001b[0;32m     31\u001b[0m df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mmerge(region_df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstation_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregion\u001b[39m\u001b[38;5;124m'\u001b[39m]], on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstation_name\u001b[39m\u001b[38;5;124m'\u001b[39m, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Region successfully mapped for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mregion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnotna()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m records.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# === 6. Clean Data ===\u001b[39;00m\n\u001b[0;32m     35\u001b[0m to_numeric_cols \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_price_tickets\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreduced_price_tickets\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseason_tickets\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minterchanges\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_entries_exits\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\maria\\anaconda3\\envs\\DataAnalytics\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\maria\\anaconda3\\envs\\DataAnalytics\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'region'"
     ]
    }
   ],
   "source": [
    "# Railway Passenger Flow Analysis (2022-2024)\n",
    "\n",
    "# === 1. Load Datasets ===\n",
    "file_2023 = 'Entries_Exits_Interchanges_2022-23.csv'\n",
    "file_2024 = 'Entries_Exits_Interchanges_2023-24.csv'\n",
    "\n",
    "# Read both CSVs\n",
    "df_2023 = pd.read_csv(file_2023)\n",
    "df_2024 = pd.read_csv(file_2024)\n",
    "\n",
    "# Add year columns\n",
    "df_2023['year'] = '2022-23'\n",
    "df_2024['year'] = '2023-24'\n",
    "\n",
    "# === 2. Standardize Column Names ===\n",
    "df_2023.columns = df_2023.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "df_2024.columns = df_2024.columns.str.strip().str.lower().str.replace(' ', '_')\n",
    "\n",
    "# === 3. Combine Datasets ===\n",
    "df = pd.concat([df_2023, df_2024], ignore_index=True)\n",
    "\n",
    "# === 4. Standardize station names ===\n",
    "df['station_name'] = df['station_name'].str.strip().str.lower()\n",
    "\n",
    "# === 5. Enrich with Region Info ===\n",
    "region_df = pd.read_excel('Region mapping.xlsx')\n",
    "region_df.columns = region_df.columns.str.strip().str.lower()\n",
    "region_df['station_name'] = region_df['station_name'].str.strip().str.lower()\n",
    "\n",
    "# Merge with region info\n",
    "df = df.merge(region_df[['station_name', 'region']], on='station_name', how='left')\n",
    "#print(f\"✅ Region successfully mapped for {df['region'].notna().sum()} out of {len(df)} records.\")\n",
    "\n",
    "# === 6. Clean Data ===\n",
    "to_numeric_cols = ['full_price_tickets', 'reduced_price_tickets', 'season_tickets', 'interchanges', 'total_entries_exits']\n",
    "for col in to_numeric_cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# === 7. Basic Aggregation by Year and Station ===\n",
    "total_by_station = df.groupby(['station_name', 'year'], as_index=False)[\n",
    "    ['full_price_tickets', 'reduced_price_tickets', 'season_tickets', 'interchanges', 'total_entries_exits']\n",
    "].sum()\n",
    "\n",
    "# Reattach region info\n",
    "total_by_station = total_by_station.merge(region_df[['station_name', 'region']], on='station_name', how='left')\n",
    "\n",
    "# === 8. Year-on-Year Growth ===\n",
    "yoy = total_by_station.pivot(index='station_name', columns='year', values='total_entries_exits').reset_index()\n",
    "yoy.columns.name = None\n",
    "yoy['growth_absolute'] = yoy['2023-24'] - yoy['2022-23']\n",
    "yoy['growth_percent'] = ((yoy['2023-24'] - yoy['2022-23']) / yoy['2022-23']) * 100\n",
    "\n",
    "# === 9. Forecast 2024-25 ===\n",
    "yoy_forecast = yoy.dropna(subset=['2022-23', '2023-24']).copy()\n",
    "forecast_values = []\n",
    "for _, row in yoy_forecast.iterrows():\n",
    "    X = np.array([[2022], [2023]])\n",
    "    y = np.array([row['2022-23'], row['2023-24']])\n",
    "    model = LinearRegression().fit(X, y)\n",
    "    forecast_values.append(model.predict([[2024]])[0])\n",
    "\n",
    "yoy_forecast['forecast_2024-25'] = forecast_values\n",
    "\n",
    "# === 10. Prepare Long Format for Power BI ===\n",
    "long_format = pd.melt(\n",
    "    yoy_forecast,\n",
    "    id_vars=['station_name'],\n",
    "    value_vars=['2022-23', '2023-24', 'forecast_2024-25'],\n",
    "    var_name='year',\n",
    "    value_name='passenger_flow'\n",
    ")\n",
    "\n",
    "# Merge region info back in (optional but useful for maps/slicers)\n",
    "long_format = long_format.merge(region_df[['station_name', 'region']], on='station_name', how='left')\n",
    "\n",
    "# === 11. Export Long Format for Power BI ===\n",
    "long_format.to_csv('passenger_flow_long.csv', index=False)\n",
    "print(\"✅ Exported reshaped long-format dataset for Power BI!\")\n",
    "\n",
    "# === 12. Plot Top 10 Forecast Stations ===\n",
    "top_10 = yoy_forecast.sort_values(by='2023-24', ascending=False).head(10)\n",
    "plt.figure(figsize=(12, 6))\n",
    "for _, row in top_10.iterrows():\n",
    "    plt.plot([2022, 2023, 2024], [row['2022-23'], row['2023-24'], row['forecast_2024-25']], marker='o', label=row['station_name'].title())\n",
    "\n",
    "plt.title('Top 10 Busiest Stations – Forecast to 2024/25')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Passenger Flow')\n",
    "plt.grid(True)\n",
    "plt.legend(bbox_to_anchor=(1, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_df.columns = region_df.columns.str.strip().str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  station_name  region\n",
      "0   abbey wood  London\n",
      "1         aber   Wales\n",
      "2     aberdare   Wales\n",
      "3    aberdovey   Wales\n",
      "4     abererch   Wales\n"
     ]
    }
   ],
   "source": [
    "print(region_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📄 Columns in 2022–23 data: ['station_name', 'full_price_tickets', 'reduced_price_tickets', 'season_tickets', 'total_entries_exits', 'interchanges', 'region', 'nlc_code', 'tlc_code', 'year']\n",
      "📄 Columns in 2023–24 data: ['station_name', 'full_price_tickets', 'reduced_price_tickets', 'season_tickets', 'total_entries_exits', 'interchanges', 'region', 'nlc_code', 'tlc_code', 'year']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in 2022–23 data:\", df_2023.columns.tolist())\n",
    "print(\"Columns in 2023–24 data:\", df_2024.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Portlethen', 'Corby', 'Redbridge', 'Lee (London)', 'West Hampstead Thameslink', 'Elstree and Borehamwood', 'Upper Holloway', 'Birkenhead North', 'Berkswell', 'Burnside (South Lanarkshire)']\n"
     ]
    }
   ],
   "source": [
    "print(df['station_name'].drop_duplicates().sample(10).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['station_name', 'Aberdovey', 'Abererch', 'Abererch', 'Achanalt', 'Achanalt', 'Achnashellach', 'Achnashellach', 'Acklington', 'Acklington', 'Altnabreac', 'Altnabreac', 'Ardgay', 'Ardlui', 'Ardlui', 'Ardwick', 'Arisaig', 'Arisaig', 'Balmossie', 'Banavie']\n"
     ]
    }
   ],
   "source": [
    "with open('Region mapping.txt', 'r', encoding='utf-8') as f:\n",
    "    preview = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "print(preview[:20])  # first few lines\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataAnalytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
